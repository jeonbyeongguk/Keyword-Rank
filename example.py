import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
import openpyxl
import time
import base64
import asyncio
from pyppeteer import launch

# í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
st.set_page_config(page_title="My App", page_icon=":smiley:", layout="wide")

def main():
    st.title("ğŸ’¡í…ŒìŠ¤íŠ¸")
    st.write("Welcome to Streamlit!")
    st.write("This is a simple example.")

if __name__ == "__main__":
    main()
    

def search_keyword(keyword):
    url = f'https://search.naver.com/search.naver?query={keyword}'

    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}
    response = requests.get(url, headers=headers)

    if response.status_code == 200:
        html = response.text
        soup = BeautifulSoup(html, 'html.parser')
        title1 = soup.select_one('#power_link_body > ul > li:nth-child(1) > div > div.title_url_area > a > span:nth-child(1)')
        st.write(title1.get_text())
        
        title2 = soup.select_one('#power_link_body > ul > li:nth-child(2) > div > div.title_url_area > a > span:nth-child(1)')
        st.write(title2.get_text())
        
        title3 = soup.select_one('#power_link_body > ul > li:nth-child(3) > div > div.title_url_area > a > span:nth-child(1)')
        st.write(title3.get_text())

    else : 
        st.write(f"Error: {response.status_code}")


input_keyword = st.text_input('ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”:', key='input_keyword')
if input_keyword:
    search_keyword(input_keyword)


def search_keyword_mo(keyword):
    url = f'https://m.search.naver.com/search.naver?query={keyword}'

    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}
    response = requests.get(url, headers=headers)

    if response.status_code == 200:
        html = response.text
        soup = BeautifulSoup(html, 'html.parser')
        title1 = soup.select_one('#power_link_body > li:nth-child(1) > div > div.tit_wrap > div > a > div.tit_area > span:nth-child(1) > mark')
        st.write(title1.get_text())
        
        title2 = soup.select_one('#power_link_body > li:nth-child(2) > div > div.tit_wrap > div > a > div.tit_area > span:nth-child(1) > mark')
        st.write(title2.get_text())
        
        title3 = soup.select_one('#power_link_body > li:nth-child(3) > div > div.tit_wrap > div > a > div.tit_area > span:nth-child(1) > mark')
        st.write(title3.get_text())

    else : 
        st.write(f"Error: {response.status_code}")


input_keyword_mo = st.text_input('ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”:', key='input_keyword_mo')
if input_keyword_mo:
    search_keyword_mo(input_keyword_mo)


async def crawl_naver_pc(keyword):
    browser = await launch()
    page = await browser.newPage()
    await page.goto(f'https://search.naver.com/search.naver?query={keyword}')
    
    # ì›í•˜ëŠ” ë‚´ìš©ì„ ê°€ì ¸ì˜¤ëŠ” ì½”ë“œë¥¼ ì‘ì„±
    # ì˜ˆë¥¼ ë“¤ì–´, í˜ì´ì§€ì˜ íŠ¹ì • ìš”ì†Œë¥¼ ì„ íƒí•˜ê³  ë‚´ìš©ì„ ê°€ì ¸ì˜¤ëŠ” ë“±ì˜ ì‘ì—…ì„ ìˆ˜í–‰
    
    # í˜ì´ì§€ ë‚´ìš©ì„ ê°€ì ¸ì˜¨ í›„ ë°˜ë“œì‹œ ë¸Œë¼ìš°ì €ë¥¼ ë‹«ì•„ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤.
    await browser.close()

input_keyword_crawl = st.text_input('ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”:', key='input_keyword_crawl')
if input_keyword_crawl:
    st.experimental_rerun()  # ì´ê²ƒìœ¼ë¡œ ë¹„ë™ê¸°ì ìœ¼ë¡œ ì½”ë“œë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•©ë‹ˆë‹¤.
