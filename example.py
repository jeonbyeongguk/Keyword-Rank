import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
import openpyxl
import time
import base64
import asyncio
from pyppeteer import launch

# í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
st.set_page_config(page_title="My App", page_icon=":smiley:", layout="wide")

def main():
    st.title("ğŸ’¡í…ŒìŠ¤íŠ¸")
    st.write("Welcome to Streamlit!")
    st.write("This is a simple example.")

if __name__ == "__main__":
    main()
    

def search_keyword(keyword):
    url = f'https://search.naver.com/search.naver?query={keyword}'

    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}
    response = requests.get(url, headers=headers)

    if response.status_code == 200:
        html = response.text
        soup = BeautifulSoup(html, 'html.parser')
        title1 = soup.select_one('#power_link_body > ul > li:nth-child(1) > div > div.title_url_area > a > span:nth-child(1)')
        st.write(title1.get_text())
        
        title2 = soup.select_one('#power_link_body > ul > li:nth-child(2) > div > div.title_url_area > a > span:nth-child(1)')
        st.write(title2.get_text())
        
        title3 = soup.select_one('#power_link_body > ul > li:nth-child(3) > div > div.title_url_area > a > span:nth-child(1)')
        st.write(title3.get_text())

    else : 
        st.write(f"Error: {response.status_code}")


input_keyword = st.text_input('ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”:', key='input_keyword')
if input_keyword:
    search_keyword(input_keyword)


def search_keyword_mo(keyword):
    url = f'https://m.search.naver.com/search.naver?query={keyword}'

    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}
    response = requests.get(url, headers=headers)

    if response.status_code == 200:
        html = response.text
        soup = BeautifulSoup(html, 'html.parser')
        title1 = soup.select_one('#power_link_body > li:nth-child(1) > div > div.tit_wrap > div > a > div.tit_area > span:nth-child(1) > mark')
        st.write(title1.get_text())
        
        title2 = soup.select_one('#power_link_body > li:nth-child(2) > div > div.tit_wrap > div > a > div.tit_area > span:nth-child(1) > mark')
        st.write(title2.get_text())
        
        title3 = soup.select_one('#power_link_body > li:nth-child(3) > div > div.tit_wrap > div > a > div.tit_area > span:nth-child(1) > mark')
        st.write(title3.get_text())

    else : 
        st.write(f"Error: {response.status_code}")


input_keyword_mo = st.text_input('ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”:', key='input_keyword_mo')
if input_keyword_mo:
    search_keyword_mo(input_keyword_mo)


async def crawl_naver_pc(keyword):
    browser = await launch()
    page = await browser.newPage()
    await page.goto(f'https://search.naver.com/search.naver?query={keyword}')
    
    # ì›í•˜ëŠ” ë‚´ìš©ì„ ê°€ì ¸ì˜¤ëŠ” ì½”ë“œë¥¼ ì‘ì„±
    # ì˜ˆë¥¼ ë“¤ì–´, í˜ì´ì§€ì˜ íŠ¹ì • ìš”ì†Œë¥¼ ì„ íƒí•˜ê³  ë‚´ìš©ì„ ê°€ì ¸ì˜¤ëŠ” ë“±ì˜ ì‘ì—…ì„ ìˆ˜í–‰
    
    # í˜ì´ì§€ ë‚´ìš©ì„ ê°€ì ¸ì˜¨ í›„ ë°˜ë“œì‹œ ë¸Œë¼ìš°ì €ë¥¼ ë‹«ì•„ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤.
    await browser.close()

input_keyword_crawl = st.text_input('ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”:', key='input_keyword_crawl')
if input_keyword_crawl:
    asyncio.get_event_loop().run_until_complete(crawl_naver_pc(input_keyword_crawl))


# ì¤‘ì•™ì— ìœ„ì¹˜í•˜ê³  í¬ê¸°ë¥¼ í‚¤ìš°ê¸° ìœ„í•´ HTML ì‚¬ìš©
st.markdown('<h1 style="text-align:center;">Countdown</h1>', unsafe_allow_html=True)
ph = st.empty()
N = 5*60
for secs in range(N,0,-1):
    mm, ss = secs//60, secs%60
    # í¬ê¸°ë¥¼ ì¡°ì ˆí•˜ê³  ê°€ìš´ë° ì •ë ¬
    ph.markdown(f'<h2 style="text-align:center;">{mm:02d}:{ss:02d}</h2>', unsafe_allow_html=True)
    time.sleep(1)
